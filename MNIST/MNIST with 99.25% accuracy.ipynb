{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\Akshay\\\\Downloads\\\\Machine Learning Competition\\\\Analytics Vidhya\\\\MNIST\\\\Images'\n",
    "\n",
    "test_path = data_dir+'\\\\Test\\\\'\n",
    "train_path = data_dir+'\\\\Train\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(train_path, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(test_path, 'Test_fCbTej3_0j1gHmj.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image = train_path+'0.png'\n",
    "plt.imshow(plt.imread(train_image))\n",
    "print(train.label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAM5ElEQVR4nO3db4hV953H8c8npkWiPjAbYtw42XZLHmxYSLqILLSELsHGjQY14FIDGxfCjg86mxZ8kL/QPAlI2LbkUWFKpHbTRBqqRKG4FSlkS6BkHNzEdNImG0wdHcZtEmhMhEbnuw/muEx17rkz55x7z9Xv+wXDvfd87znny8WP59z7O/f+HBECcO27ru0GAPQHYQeSIOxAEoQdSIKwA0lc38+d2eajf6DHIsLzLa91ZLe9wfZvbb9r+7E62wLQW646zm57iaTfSVovaVLS65K2R8RvStbhyA70WC+O7OskvRsR70XEnyTtk7S5xvYA9FCdsN8q6dScx5PFsj9je9j2mO2xGvsCUFOdD+jmO1W44jQ9IkYljUqcxgNtqnNkn5Q0NOfxGkln6rUDoFfqhP11Sbfb/qLtz0v6hqSDzbQFoGmVT+Mj4oLtEUn/KWmJpD0R8VZjnQFoVOWht0o74z070HM9uagGwNWDsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BE5fnZJcn2SUkfS7oo6UJErG2iKQDNqxX2wj9ExB8a2A6AHuI0HkiibthD0i9sH7M9PN8TbA/bHrM9VnNfAGpwRFRf2f7LiDhj+2ZJRyT9W0S8WvL86jsDsCAR4fmW1zqyR8SZ4vaspAOS1tXZHoDeqRx228tsr7h0X9LXJZ1oqjEAzarzafwqSQdsX9rOixFxuJGusCjLly/vWHvqqadK13300UdL6xMTE6X1AwcOlNZHR0c71t5///3SddGsymGPiPck3dlgLwB6iKE3IAnCDiRB2IEkCDuQBGEHkqh1Bd2id8YVdJWsWLGitP7aa691rN1xxx1Nt7MoH3zwQcfahg0bStcdHx9vup0UenIFHYCrB2EHkiDsQBKEHUiCsANJEHYgCcIOJME4+wBYtmxZaf3FF18srW/atKnJdvrmhRdeKK3v2LGjT51cWxhnB5Ij7EAShB1IgrADSRB2IAnCDiRB2IEkmpjYETXdfffdpfWrdRy9m/Pnz7fdQioc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCb7PPgD27dtXWt+2bVtp/aOPPupY27NnT+m6zz77bGm9myeffLK0/sgjj3SszczMlK77wAMPlNYPHTpUWs+q8vfZbe+xfdb2iTnLbrR9xPY7xe3KJpsF0LyFnMb/SNLlU3c8JuloRNwu6WjxGMAA6xr2iHhV0oeXLd4saW9xf6+kLQ33BaBhVa+NXxURU5IUEVO2b+70RNvDkoYr7gdAQ3r+RZiIGJU0KvEBHdCmqkNv07ZXS1Jxe7a5lgD0QtWwH5R06Xd+d0h6pZl2APRK19N42y9J+pqkm2xPSvqOpN2Sfmr7YUm/l1Q+EIxSS5curbX+yMhIx1q3Mfy6JicnK6973XXlx5r169eX1hlnX5yuYY+I7R1K9zTcC4Ae4nJZIAnCDiRB2IEkCDuQBGEHkuCnpPtg165dpfV77qk3sPHQQw91rL388sul695///2l9S1byr/2sHXr1tJ6HevWrSutL1++vLR+7ty5Jtu56nFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGfvg9OnT5fWb7jhhlrbv/feezvWun0NtGzdtr399tul9YsXL/apk2sDR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9j7oNh7crb5kyZLK+x7kcfRuTp06VVo/f/58nzq5NnBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHBH925ndv51dRYaGhkrrjz/+eGl9586dlff96aefltb3799fWu82rfKqVasW3dMlGzduLK0fPny48ravZRHh+ZZ3PbLb3mP7rO0Tc5Y9bfu07ePF331NNgugeQs5jf+RpA3zLP9+RNxV/P282bYANK1r2CPiVUkf9qEXAD1U5wO6EdtvFKf5Kzs9yfaw7THbYzX2BaCmqmH/gaQvSbpL0pSk73Z6YkSMRsTaiFhbcV8AGlAp7BExHREXI2JG0g8llU+3CaB1lcJue/Wch1slnej0XACDoes4u+2XJH1N0k2SpiV9p3h8l6SQdFLSzoiY6rozxtkruf768p8duPPOOytv+5NPPimtd/vt9ueee660PjIysuieLmGcvZpO4+xdf7wiIrbPs/j52h0B6CsulwWSIOxAEoQdSIKwA0kQdiAJfkr6KnDhwoXS+rFjx/rUyZVWrux4pXRXn332WWn93LlzlbeNK3FkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGdHqW5fM33wwQcrb3tmZqa03m0cHovDkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHaVuueWW0ro9768WL8ihQ4dK6+Pj45W3jStxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnR2u6jeHzffZmdT2y2x6y/UvbE7bfsv2tYvmNto/Yfqe4rT5bAICeW8hp/AVJuyLibyT9vaRv2r5D0mOSjkbE7ZKOFo8BDKiuYY+IqYgYL+5/LGlC0q2SNkvaWzxtr6QtvWoSQH2Les9u+wuSvizp15JWRcSUNPsfgu2bO6wzLGm4XpsA6lpw2G0vl/QzSd+OiD8u9AsQETEqabTYRlRpEkB9Cxp6s/05zQb9JxGxv1g8bXt1UV8t6WxvWgTQhK5Hds8ewp+XNBER35tTOihph6Tdxe0rPekQ16yhoaG2W0hlIafxX5H0z5LetH28WPaEZkP+U9sPS/q9pG29aRFAE7qGPSJ+JanTG/R7mm0HQK9wuSyQBGEHkiDsQBKEHUiCsANJ8BVXlFqzZk3Ptn369OmebRtX4sgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo5SGzdu7Nm2Dx8+3LNt40oc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZUWp6erpn2960aVNp/ZlnnunZvjPiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSSxkfvYhST+WdIukGUmjEfGc7acl/auk/y2e+kRE/LxXjaIdu3fvLq3fdtttpfWlS5d2rG3bxizf/bSQi2ouSNoVEeO2V0g6ZvtIUft+RPx779oD0JSFzM8+JWmquP+x7QlJt/a6MQDNWtR7dttfkPRlSb8uFo3YfsP2HtsrO6wzbHvM9litTgHUsuCw214u6WeSvh0Rf5T0A0lfknSXZo/8351vvYgYjYi1EbG2gX4BVLSgsNv+nGaD/pOI2C9JETEdERcjYkbSDyWt612bAOrqGnbblvS8pImI+N6c5avnPG2rpBPNtwegKY6I8ifYX5X0X5Le1OzQmyQ9IWm7Zk/hQ9JJSTuLD/PKtlW+MwC1RYTnW9417E0i7EDvdQo7V9ABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS6PeUzX+Q9P6cxzcVywbRoPY2qH1J9FZVk739VadCX7/PfsXO7bFB/W26Qe1tUPuS6K2qfvXGaTyQBGEHkmg77KMt77/MoPY2qH1J9FZVX3pr9T07gP5p+8gOoE8IO5BEK2G3vcH2b22/a/uxNnroxPZJ22/aPt72/HTFHHpnbZ+Ys+xG20dsv1PczjvHXku9PW37dPHaHbd9X0u9Ddn+pe0J22/Z/laxvNXXrqSvvrxufX/PbnuJpN9JWi9pUtLrkrZHxG/62kgHtk9KWhsRrV+AYftuSeck/Tgi/rZY9qykDyNid/Ef5cqIeHRAenta0rm2p/EuZitaPXeacUlbJP2LWnztSvr6J/XhdWvjyL5O0rsR8V5E/EnSPkmbW+hj4EXEq5I+vGzxZkl7i/t7NfuPpe869DYQImIqIsaL+x9LujTNeKuvXUlffdFG2G+VdGrO40kN1nzvIekXto/ZHm67mXmsujTNVnF7c8v9XK7rNN79dNk04wPz2lWZ/ryuNsI+39Q0gzT+95WI+DtJ/yjpm8XpKhZmQdN498s804wPhKrTn9fVRtgnJQ3NebxG0pkW+phXRJwpbs9KOqDBm4p6+tIMusXt2Zb7+X+DNI33fNOMawBeuzanP28j7K9Lut32F21/XtI3JB1soY8r2F5WfHAi28skfV2DNxX1QUk7ivs7JL3SYi9/ZlCm8e40zbhafu1an/48Ivr+J+k+zX4i/z+Snmyjhw59/bWk/y7+3mq7N0kvafa07jPNnhE9LOkvJB2V9E5xe+MA9fYfmp3a+w3NBmt1S719VbNvDd+QdLz4u6/t166kr768blwuCyTBFXRAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/AQXz/WMibrYHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image = train_path+'1.png'\n",
    "plt.imshow(plt.imread(train_image))\n",
    "print(train.label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imread(train_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage.transform import resize\n",
    "l1 = []\n",
    "i = random.choice(train.index)\n",
    "img_name = train.filename[i]\n",
    "for i in train.filename:\n",
    "    img_path = os.path.join(data_dir, 'Train', i)\n",
    "    img = plt.imread(img_path)\n",
    "    img = resize(img, (28, 28))\n",
    "    img = img.astype('float32')\n",
    "    l1.append(img)\n",
    "train_x = np.stack(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "i = random.choice(test.index)\n",
    "img_name = test.filename[i]\n",
    "for i in test.filename:\n",
    "    img_path = os.path.join(data_dir, 'Test', i)\n",
    "    img = plt.imread(img_path)\n",
    "    img = resize(img, (28, 28))\n",
    "    img = img.astype('float32')\n",
    "    l1.append(img)\n",
    "test_x = np.stack(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "import keras\n",
    "train_y = le.fit_transform(train.label)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 28, 28, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28, 4)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())    \n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "    \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "    \n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        2368      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 694,410\n",
      "Trainable params: 693,514\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape= image_shape, activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())    \n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49000/49000 [==============================] - 137s 3ms/step - loss: 0.1054 - accuracy: 0.9676\n",
      "Epoch 2/20\n",
      "49000/49000 [==============================] - 130s 3ms/step - loss: 0.0356 - accuracy: 0.9886\n",
      "Epoch 3/20\n",
      "49000/49000 [==============================] - 148s 3ms/step - loss: 0.0278 - accuracy: 0.9915\n",
      "Epoch 4/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0179 - accuracy: 0.9941\n",
      "Epoch 5/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0180 - accuracy: 0.9941\n",
      "Epoch 6/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 7/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0128 - accuracy: 0.9958\n",
      "Epoch 8/20\n",
      "49000/49000 [==============================] - 162s 3ms/step - loss: 0.0124 - accuracy: 0.9960\n",
      "Epoch 9/20\n",
      "49000/49000 [==============================] - 156s 3ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 10/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 11/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0114 - accuracy: 0.9965\n",
      "Epoch 12/20\n",
      "49000/49000 [==============================] - 156s 3ms/step - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 13/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 14/20\n",
      "49000/49000 [==============================] - 156s 3ms/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 15/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 16/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 17/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 18/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 19/20\n",
      "49000/49000 [==============================] - 158s 3ms/step - loss: 0.0105 - accuracy: 0.9970\n",
      "Epoch 20/20\n",
      "49000/49000 [==============================] - 155s 3ms/step - loss: 0.0051 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x15aeeacce10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=20, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('MN4.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
